

# Mémoire de fin d'année



Dorian Blanchard - Rendu du 7 novembre 2023



**Titre :** Histoire et Philosophie de l'Information

**Sujet :** L'information est omniprésente. Son étymologie latine "*informare*" signifie donner forme ou se former une idée de quelque chose. Dès la préhistoire, les humains ont donc naturellement élaboré des techniques pour stocker et communiquer des formes à travers le dessin et la gravure, permettant hypothétiquement les premiers calculs et systèmes de comptage des unités et du temps. Puis la sédentarisation bouleversa les comportements sociaux, le développement de l'agriculture a engendré les premières villes et sociétés, rendant nécessaire le stockage de biens à l'aide de la vannerie, du tissage et de la poterie, causant en contrepartie les premiers conflits d'envergure.

L'écriture qui marque le début de l'Antiquité a fourni à l'humanité une nouvelle interface pour transmettre les connaissances aux générations futures, mais aussi pour légiférer les communautés naissantes, permettant ainsi de lister les comportements allant à l'encontre du bien commun et la sanction donnée à ceux qui les réaliserai. Certaines philosophes comme Socrate en feront les frais, avant lui Thalès et Pythagore ont posé les bases des mathématiques. Aristote quant à lui, posera celles de la physique et de la biologie.

Le développement des symboles ont permit de représenter les sons de la voix, avec le langage et les idées qui en découlent, voire en composer de nouvelles en les mélangeant, formant petit à petit les bases de la connaissance et de la pensée combinatoire logique trouvant sa source dans la Grèce Antique. Grâce aux conquêtes d'Alexandre Le Grand, ce savoir se déplacera autour de la méditerranée pour finir par converger vers la plus connue des villes portant son nom, Alexandrie d’Égypte. Véritable lieu culturel et intellectuel, sa bibliothèque recensa multitudes de textes antiques et les premiers mécaniciens y concevront des machines utilisant les forces mécaniques en introduisant celles de la vapeur produite par de l'eau chauffée.

Ce savoir sera transmis aux Romains lors de l'extension de leur empire, dont la chute marque le début du moyen-âge. Pendant cette période, l'accumulation de connaissance a été récupérée par le peuple Arabe qui contribua fortement à la science durant ce que les historiens appellent l'âge d'or de l'Islam, perpétrant la tradition de traduction de textes antiques, en les complétant grâce aux sciences indiennes et leurs propres recherches et expérimentations. Leur système de numérotation se popularisera, remplaçant les chiffres romains qui étaient peu pratique pour le calcul, et leurs travaux seront eux même traduits pour être transmis au monde occidental.

Deux dizaines d'années avant l'époque moderne, la typographie et l'impression seront démocratisés par Gutenberg, révolutionnant l'écriture en l'automatisant à l'aide d'outils et de machines. S'en suivra alors le siècle des lumières, un courant philosophique et scientifique sans précédent qui rétablira la vérité quand à l'astronomie, prouvant que le soleil est au centre de notre système héliocentrique, mettant ainsi fin à l'affirmation disant jusque là que notre Terre en était le centre, et par conséquent au système géocentrique lié. La pédagogie sera modernisée d'après les travaux de Rousseau, et Vauban introduira le concept et l'étude des systèmes. Beaucoup d'inventions verront le jours dont les premières machines à calculer, accompagnées par le binaire formalisé par Leibniz.

Au 19 ème siècle les machines et calculateurs mécaniques seront améliorés, automatisant de plus en plus de tâches pénibles, notamment dans le milieu du textile qui sera à l'origine de la de la science du traitement et de l’écriture de l'information par des machines mécaniques. Cette science sera appelée mécanographie, et son inventeur sera le créateur d'une entreprise qui deviendra le géant de l'informatique IBM. Ces machines se développeront jusqu'à devenir électromécaniques, puis entièrement électronique à l'aide des découvertes faites dans ce domaine. Initiées par l'ancêtre du condensateur nommé bouteille de Leyde, et la pile de Volta qui a instantanément obtenu une renomme mondiale, déclenchant un intérêt notable pour ce domaine de recherche qui a donner lieu aux circuits imprimés et semi-conducteurs toujours présents dans les machines actuelles. A cette même période, le téléphone fit son apparition, accompagné par l'imagerie numérique qui se développa avec l'invention de l'appareil photo puis des iconoscope et écrans à tubes cathodiques. Grâce à l'ensemble de ces découvertes, la structure et les composants des calculateurs évolueront jusqu'à former des ordinateurs capables de tout calculer comme l'avait imaginé Charles Babbage quand il a pensé la machine analytique, ou Turing lors de son expérience de pensée présentant sa machine éponyme.

Les guerres sont à l'origine de grandes inventions technologiques comme l'encryption, qui a bien évoluer depuis ses origines antiques avec la scytale spartiate. Les deux guerres mondiales ont donc logiquement mobilisé la puissance de calcul et le besoin de gestion de l'information pour détecter les ennemis à temps, gérer ses troupes, et déchiffrer les communications. À la fin de ses deux guerres, de nouvelles perspectives se sont présentées, les chercheurs et ingénieurs ont imaginé de nouvelles manières d'utiliser l'informatique en dehors des applications militaires, qu'elle à eu jusque là lors de projets top secrets. Rapidement rattrapés par la crainte d'une attaque nucléaire de la Russie sur les États-Unis provoquant la Guerre Froide, naîtrons alors les besoin de calculs en temps réel, technologie qui a par la suite été popularisée dans le domaine des réservations et du paiement bancaire.

L'informatique s'implanta si rapidement dans la société que les penseurs ont émis de nouvelles idées et disciplines comme la cybernétique. Elle représente l'étude des mécanismes d'information des systèmes complexes et leur analogies entre les organismes vivants et les machines, laissant entrevoir les prémisses d'une symbiose avec la technologie et ainsi le transhumanisme. L'information et son algorithmisation seront théorisées, elles amèneront à de nouveaux concepts philosophiques comme le fonctionnalisme, le computionnalisme qui en découle, et plus récemment émergea une philosophie de l'information.

Quant à la réalisation technique de logiciels, les développeurs créerons des langages de plus en plus haut niveau permettant de concevoir des applications plus fiable rapidement. Les programmes seront de plus en plus complexes et leurs calculs de plus en plus précis, permettant à l'humanité d'aller sur la lune, et devenant capable d'imiter l'humain, donnant lieux aux premières intelligences artificielles. De nouvelles interfaces ont vu le jour, qu'elles soient physique avec la souris ou le tactile, ou visuelles comme les interfaces graphiques qui ont remplacer la ligne de commande et leurs systèmes de fenêtres, plus récemment supplantées par la réalité augmenté, virtuelle, ou mixte.

Les recherches et compréhension récente dans le domaine de la bio-informatique ou de la physique quantique permettrons une nouvelles manière de stocker l'information dans de l'ADN ou des bits quantiques appelés qubits. Toutes ces nouvelles technologies ouvrent de nouveaux horizons, repoussant les limites du possible en solutionnant de multiples problèmes, nous permettant par la suite d'en trouver de nouveaux. Les systèmes de communication sont rapidement passés du télégraphe à l'appel téléphonique, jusqu'à l’avènement d'internet à la fin du siècle dernier. Cette mondialisation de l'information et son instantanéité nous permettent aujourd'hui de collaborer n'importe quand avec n'importe qui, où que l'on soit, d'avoir accès à des connaissances et de trouver réponse à nos questions.

Après mes recherches sur les origines des systèmes de gestion de l'information et des différant penseurs qui en sont à l'origine, j'ai pu remarquer à travers l'Histoire que les inventions de savants et créateurs ne sortent que rarement de nulle part. Leurs origines proviennent souvent de (re)découvertes des principes existant, qu'ils compilent et les réutilisent à leur manières, améliorant les idées de leurs prédécesseur et réalisant de meilleurs outils à force d'itérations innovantes. Certaines personnes seront les pionnières, mais généralement accompagnés par d'autres car les idées naissent d'une combinaison d'autres déjà existantes dans le contexte mondial à un moment donné. Il est en effet impossible de savoir qui à eu l'idée d'une chose pour la première fois, on ne retiendra naturellement que la première personne à avoir populariser le termes ou l'idée, parfois à travers la commercialisation d'un produit, d'autre fois grâce à une publication scientifique ou dépôt d'un brevet, et certaines informations plus ésotériques ne se transmettrons que par la parole, conservant ainsi un secret relatif.

L'informatique moderne comme toutes les technologies, explore d'abord les possibilités en créant de multiples outils et techniques, puis sa démocratisation nécessite une standardisation. Des consensus sont alors formés et établissent des normes, simplifiant et harmonisant les outils et techniques en les rendant universels. Établissant ainsi des bases communes et des protocoles à suivre pour établir des systèmes de communications sécurisés. Suite à l'analyse du passé et de son bilan, je ferais donc un lien en analysant les pratiques actuelles résultant de ces standardisation, avec les outils et méthodologies dont on a hérité.

L'avant dernière partie, présentera brièvement mon parcours et tentera à travers un essai philosophique, d'exposer ma pensée, de résumer les principaux concepts informationnels, de redéfinir certains mots, et enfin d'introduire la dernière partie. Elle viendra définitivement répondre à la problématique à l'aide d’exemples techniques vulgarisés et de maquettes d'interfaces logiciels permettant de faciliter la compréhension pour tout lecteur.





**Problématique :** L'informatique, étymologiquement automatisation de la gestion de l'information, est un domaine récent et complexe, qui soulève beaucoup d'avancés technologiques mais également de craintes et de questionnements. La programmation à l'origine des logiciels qui nous permettent d'utiliser le matériel informatique, n'était en 2022 pratiquée par seulement 0.35% de la population. Elle requiert une rigueur suffisante pour dans un premier temps passer la compilation si elle a lieu, puis l'exécution du programme en résultant, et enfin les tests du comportement voulu, dans le but de vérifier que l'on a correctement implémenté la solution à notre problème informationnel. Une fois que tout cela est satisfait, il faut rendre le programme robuste afin d'assurer sa pérennité tout au long du développement des nouvelles fonctionnalités qui s'accumuleront inexorablement, et ce afin que toutes celles existantes restent fonctionnelles, ce que l'intégration et le développement continu solutionne, permettant d'assurer la qualité d'un logiciel au fil de son développement.

Les outils de développeurs actuels possèdent bien des avantages mais aussi des inconvénients, des biais sont introduits dans leurs pratiques, constituée des étapes décrites précédemment. Actuellement, l'apprentissage de ces étapes et les coût de formation d'un nouvel employé en informatique sont importants. Simplifier la prise en main d'un projet informatique me semble être une opportunité technologique intéressante, qui permettrait à l'industrie informatique de se concentrer sur sa finalité plutôt que l'organisation de sa réalisation. Dans cette dernière, la matière première est la pensée du développeur, c'est l'acteur principal à l'origine des algorithmes qui régissent la gestion de l'information. Ils réalisent des logiciels pour de multiples industries et sont pourtant, selon moi, les cordonniers les plus mal chaussés, on parle souvent d'expérience utilisateur, mais l'expérience développeur reste à désirer, voire archaïque. Selon moi nous sommes encore encore au moyen âge de l'informatique.

Je souhaite proposer des améliorations de l'expérience de développement à la manière de John Backus qui en créant Fortran à permis d'optimiser par 10 le temps de développement, de Vannevar Bush qui a imaginé un web hypertexte et les wiki permettant de relier des pages, et des idées accessibles en un simple clic grâce aux chercheurs du Xerox Parc qui ont inventer la souris, remplacer la ligne de commande par des interfaces graphiques, ou encore inventé la technologie WYSIWYG.

Bien que la ligne de commande et le texte fasse partie intégrante de la culture informatique, je pense que l'on peut aujourd'hui créer un environnement de développement moderne, qui permette de garder les habitudes que l'on à sur les éditeurs de texte sans pour autant ressembler à un bloc note, avec une interface graphique, claire et épurée, permettant la visualisation du code grâce à la technologie WYSIWYG, tout en reprenant des concepts éprouvés et familiers comme les raccourcis claviers, la navigation de fichiers et sa notion de chemin d'accès permettant de visualiser un seul endroit à la fois, ou encore l'historique permettant de retracer d'où on vient.

La **question fondamentale** à laquelle je répondrait sera donc "*Comment repenser la gestion de l'information pour moderniser l'expérience développeur ?*".

**Questions annexes :** 

- Pourquoi la programmation est-elle aussi peu démocratisée ?
- Pourquoi un outil censé résoudre un problème en cause parfois des bloquants ?
- Qu'elle est l'origine des bugs ?
- De quoi est composé un système d'information ?
- Comment faire un logiciel en tant que service ?
- Comment l'interface permet et conditionne l’accès aux fonctionnalités ? 